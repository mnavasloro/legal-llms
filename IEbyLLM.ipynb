{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from gatenlp import Document\n",
    "from gatenlp.corpora import ListCorpus\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import ollama\n",
    "from pydantic import BaseModel\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from GatenlpUtils import loadCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    load_dotenv()\n",
    "\n",
    "    user_email = os.getenv(\"USEREMAIL\")  # Enter your email here\n",
    "    password = os.getenv(\"PASSWORD\")  # Enter your password here\n",
    "\n",
    "    # Fetch Access Token\n",
    "\n",
    "    # Define the URL for the authentication endpoint\n",
    "    auth_url = \"http://localhost:8080/api/v1/auths/signin\"\n",
    "\n",
    "    # Define the payload with user credentials\n",
    "    auth_payload = json.dumps({\"email\": user_email, \"password\": \"admin\"})\n",
    "\n",
    "    # Define the headers for the authentication request\n",
    "    auth_headers = {\"accept\": \"application/json\", \"content-type\": \"application/json\"}\n",
    "\n",
    "    # Make the POST request to fetch the access token\n",
    "    auth_response = requests.post(auth_url, data=auth_payload, headers=auth_headers)\n",
    "\n",
    "    # Extract the access token from the response\n",
    "    access_token = auth_response.json().get(\"token\")\n",
    "except Exception as e:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Event(BaseModel):\n",
    "  event: str\n",
    "  event_who: str\n",
    "  event_when: str\n",
    "  event_what: str\n",
    "  event_type: str\n",
    "\n",
    "class EventList(BaseModel):\n",
    "  events: list[Event]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def askChatbot(model, role, instruction, content):\n",
    "    chat_url = \"http://localhost:11434/api/chat\"\n",
    "\n",
    "    # Define the headers for the chat completion request, including the access token\n",
    "    chat_headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"content-type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {access_token}\",\n",
    "    }\n",
    "\n",
    "    # Define the payload for the chat completion request\n",
    "    chat_payload = json.dumps(\n",
    "        {\n",
    "            \"stream\": False,\n",
    "            \"model\": model,\n",
    "            \"temperature\": 0.0,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": role},  # System role with additional context\n",
    "                {\"role\": \"user\", \"content\": f\"{instruction}\\n\\n{content}\"},  # User message with instruction and text\n",
    "            ],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Make the POST request to the chat completion endpoint\n",
    "    chat_response = requests.post(chat_url, data=chat_payload, headers=chat_headers)\n",
    "    #print(chat_response.json()[\"message\"][\"content\"])\n",
    "    structured_response = EventList.model_validate_json(chat_response.json())\n",
    "    return chat_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def askChatbotLocal(model, role, instruction, content):\n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model = model,\n",
    "            options = {\n",
    "                'temperature': 0\n",
    "            }, \n",
    "            format = EventList.model_json_schema(),  # Use Pydantic to generate the schema or format=schema\n",
    "            messages=\n",
    "            [\n",
    "                {\"role\": \"system\", \"content\": role},  # System role with additional context\n",
    "                {\"role\": \"user\", \"content\": f\"{instruction}\\n\\n{content}\"},  # User message with instruction and text\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        chat_response = response['message']['content']\n",
    "        structured_response = EventList.model_validate_json(response.message.content)\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(f\"Error with model {model}: {str(e)}\")\n",
    "\n",
    "    return chat_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded input/annotated/train/CASE OF MURUZHEVA v. RUSSIA.xml into corpus\n",
      "Loaded input/annotated/train/CASE OF O.C.I. AND OTHERS v. ROMANIA.xml into corpus\n",
      "Loaded input/annotated/train/CASE OF EGILL EINARSSON v. ICELAND (No. 2).xml into corpus\n",
      "Loaded input/annotated/train/CASE OF HOINESS v. NORWAY.xml into corpus\n",
      "Loaded input/annotated/train/CASE OF MOSKALEV v. RUSSIA.xml into corpus\n",
      "Loaded input/annotated/train/CASE OF RESIN v. RUSSIA.xml into corpus\n",
      "Loaded input/annotated/train/CASE OF S.V. v. ITALY.xml into corpus\n",
      "Loaded input/annotated/train/CASE OF YERMAKOVICH v. RUSSIA.xml into corpus\n",
      "Loaded input/annotated/train/CASE OF S.N. v. RUSSIA.xml into corpus\n",
      "Loaded input/annotated/train/CASE OF PAKHTUSOV v. RUSSIA.xml into corpus\n",
      "Loaded input/annotated/train/CASE OF OTGON v. THE REPUBLIC OF MOLDOVA.xml into corpus\n",
      "Loaded input/annotated/train/CASE OF SHVIDKIYE v. RUSSIA.xml into corpus\n",
      "Loaded input/annotated/train/CASE OF SIDOROVA v. RUSSIA.xml into corpus\n",
      "Loaded input/annotated/train/CASE OF PANYUSHKINY v. RUSSIA.xml into corpus\n",
      "Loaded input/annotated/train/CASE OF VISY v. SLOVAKIA.xml into corpus\n",
      "Loaded input/annotated/train/CASE OF SOLCAN v. ROMANIA.xml into corpus\n",
      "Loaded input/annotated/train/CASE OF NODI v. HUNGARY.xml into corpus\n",
      "Loaded input/annotated/train/CASE OF YEVGENIY ZAKHAROV v. RUSSIA.xml into corpus\n",
      "Loaded input/annotated/train/CASE OF KOSAITE - CYPIENE AND OTHERS v. LITHUANIA.xml into corpus\n",
      "Loaded input/annotated/train/CASE OF STANA v. ROMANIA.xml into corpus\n",
      "Loaded input/annotated/train/CASE OF DOKTOROV v. BULGARIA.xml into corpus\n",
      "Loaded input/annotated/train/CASE OF YAKUSHEV v. UKRAINE.xml into corpus\n",
      "Loaded input/annotated/train/CASE OF M.T. v. UKRAINE.xml into corpus\n",
      "Loaded input/annotated/train/CASE OF LOZOVYYE v. RUSSIA.xml into corpus\n",
      "Loaded input/annotated/dev/CASE OF BIGUN v. UKRAINE.xml into corpus\n",
      "Loaded input/annotated/dev/CASE OF BELYAYEV AND OTHERS v. UKRAINE.xml into corpus\n",
      "Loaded input/annotated/dev/CASE OF ALTAY v. TURKEY (No. 2).xml into corpus\n",
      "Loaded input/annotated/test/CASE OF CABUCAK v. GERMANY.xml into corpus\n",
      "Loaded input/annotated/test/CASE OF CAN v. TURKEY.xml into corpus\n",
      "Loaded input/annotated/test/CASE OF CRISTIAN CATALIN UNGUREANU v. ROMANIA.xml into corpus\n",
      "All documents loaded into the corpus.\n",
      "Documents in corpus: 30\n"
     ]
    }
   ],
   "source": [
    "corpus = loadCorpus()\n",
    "print(f\"Documents in corpus: {len(corpus)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"gemma3:12b\",\n",
    "          \"mistral:latest\"\n",
    "]\n",
    "\"\"\"\n",
    "models = [\"gemma3:12b\",\n",
    "          \"chevalblanc/claude-3-haiku:latest\",\n",
    "          \"incept5/llama3.1-claude:latest\",\n",
    "          \"llama3.3:latest\",\n",
    "          \"deepseek-r1:8b\",\n",
    "          \"mistral:latest\"\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "event_definitions = \"\"\"\n",
    "You are an expert in legal text analysis. Here are the definitions of legal events:\n",
    "- Event: Relates to the extent of text containing contextual event-related information. \n",
    "- Event_who: Corresponds to the subject of the event, which can either be a subject, but also an object (i.e., an application). \n",
    "    Examples: applicant, respondent, judge, witness\n",
    "- Event_what: Corresponds to the main verb reflecting the baseline of all the paragraph. Additionally, we include thereto a complementing verb or object whenever the core verb is not self-explicit or requires an extension to attain a sufficient meaning.\n",
    "    Examples: lodged an application, decided, ordered, dismissed\n",
    "- Event_when: Refers to the date of the event, or to any temporal reference thereto.\n",
    "- Event_circumstance: Meaning that the event correspond to the facts under judgment.\n",
    "- Event_procedure: The events belongs to the procedural dimension of the case.\n",
    "\n",
    "Events contain the annotations event_who, event_what and event_when. Events can be of type event_circumstance and event_procedure.\n",
    "\"\"\"\n",
    "\n",
    "instruction = \"Analyze the provided text and extract the legal events. Provide the results in a structured format. Obviously, Event_who, Event_what and Event_when can only appear within an Event. If you find an event, also classify it into an event_circumstance or event_procedure. Do not invent additional information.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:   0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing document: file:/C:/Users/mnavas/CASE%20OF%20MURUZHEVA%20v.%20RUSSIA.docx\n",
      "Using model: gemma3:12b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-23 20:07:50,957|INFO|httpx|HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from gemma3:12b:\n",
      "{\"events\": [\n",
      "    {\n",
      "        \"event\": \"The case originated in an application (no. 62526/15) against the Russian Federation lodged with the Court under Article 34 of the Convention for the Protection of Human Rights and Fundamental Freedoms (\\\"the Convention\\\") by a Russian national, Ms Leyla Khamarzovna Muruzheva (\\\"the applicant\\\")\",\n",
      "        \"event_who\": \"Leyla Khamarzovna Muruzheva (the applicant)\",\n",
      "        \"event_when\": \"11 December 2015\",\n",
      "        \"event_what\": \"lodged an application\",\n",
      "        \"event_type\": \"event_procedure\"\n",
      "    },\n",
      "    {\n",
      "        \"event\": \"The applicant was represented by Ms V. Kogan and Mr E. Wesselink from the Stichting Russian Justice Initiative, an NGO based in Moscow. The Russian Government (\\\"the Government\\\") were initially represented by Mr G. Matyushkin, Representative of the Russian Federation to the European Court of Human Rights, and then by his successor in that office, Mr M. Galperin.\",\n",
      "        \"event_who\": \"applicant, Russian Government\",\n",
      "        \"event_when\": \"N/A\",\n",
      "        \"event_what\": \"were represented\",\n",
      "        \"event_type\": \"event_procedure\"\n",
      "    },\n",
      "    {\n",
      "        \"event\": \"The applicant complained about the authorities’ failure to enforce the judgment of 25 June 2014 granting her a residence order in respect of her children.\",\n",
      "        \"event_who\": \"applicant\",\n",
      "        \"event_when\": \"25 June 2014\",\n",
      "        \"event_what\": \"complained about failure to enforce\",\n",
      "        \"event_type\": \"event_circumstance\"\n",
      "    },\n",
      "    {\n",
      "        \"event\": \"The application was communicated to the Government.\",\n",
      "        \"event_who\": \"application, Government\",\n",
      "        \"event_when\": \"25 April 2016\",\n",
      "        \"event_what\": \"was communicated\",\n",
      "        \"event_type\": \"event_procedure\"\n",
      "    }\n",
      "]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:   0%|          | 0/30 [03:16<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m annotations_list = []\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Iterate over models\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mUsing model: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<stringsource>:69\u001b[39m, in \u001b[36mcfunc.to_py.__Pyx_CFunc_b0409f__29_pydevd_sys_monitoring_cython_object__lParen__etc_to_py_4code_4line.wrap\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1470\u001b[39m, in \u001b[36m_pydevd_sys_monitoring_cython._line_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1591\u001b[39m, in \u001b[36m_pydevd_sys_monitoring_cython._internal_line_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1950\u001b[39m, in \u001b[36m_pydevd_sys_monitoring_cython._do_wait_suspend\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/jurix25/legal-llms/.venv/lib/python3.12/site-packages/debugpy/_vendored/pydevd/pydevd.py:2188\u001b[39m, in \u001b[36mPyDB.do_wait_suspend\u001b[39m\u001b[34m(self, thread, frame, event, arg, exception_type)\u001b[39m\n\u001b[32m   2185\u001b[39m             from_this_thread.append(frame_custom_thread_id)\n\u001b[32m   2187\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._threads_suspended_single_notification.notify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[32m-> \u001b[39m\u001b[32m2188\u001b[39m         keep_suspended = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace_suspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2190\u001b[39m frames_list = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2192\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[32m   2193\u001b[39m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/jurix25/legal-llms/.venv/lib/python3.12/site-packages/debugpy/_vendored/pydevd/pydevd.py:2257\u001b[39m, in \u001b[36mPyDB._do_wait_suspend\u001b[39m\u001b[34m(self, thread, frame, event, arg, trace_suspend_type, from_this_thread, frames_tracker)\u001b[39m\n\u001b[32m   2254\u001b[39m                 queue.put(internal_cmd)\n\u001b[32m   2255\u001b[39m                 wait_timeout = TIMEOUT_FAST\n\u001b[32m-> \u001b[39m\u001b[32m2257\u001b[39m         \u001b[43mnotify_event\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2258\u001b[39m         notify_event.clear()\n\u001b[32m   2260\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/threading.py:655\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    653\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    654\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m655\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/threading.py:359\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m         gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    361\u001b[39m         gotit = waiter.acquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "viaWeb = False\n",
    "results = []\n",
    "# Iterate over documents and models\n",
    "for doc in tqdm(corpus, desc=\"Processing documents\"):\n",
    "    doc_dict = {\"Document\": doc.features.get(\"gate.SourceURL\")}\n",
    "    print(f\"Processing document: {doc.features.get(\"gate.SourceURL\")}\")\n",
    "    \n",
    "    # Combine all procedure texts for the document\n",
    "    procedure_texts = []\n",
    "    annotations = doc.annset(\"Section\")\n",
    "    procedure_annotations = annotations.with_type(\"Procedure\")\n",
    "    for ann in procedure_annotations:\n",
    "        procedure_text = doc.text[ann.start:ann.end]\n",
    "        procedure_texts.append(procedure_text)\n",
    "    combined_procedure_text = \" \".join(procedure_texts)\n",
    "    #print(f\"Combined procedure text: {combined_procedure_text}\")\n",
    "    \n",
    "    annotations_list = []\n",
    "    # Iterate over models\n",
    "    for model in models:\n",
    "        try:\n",
    "            print(f\"Using model: {model}\")\n",
    "            \n",
    "            # Call the chatbot with role, instruction, and content\n",
    "            if viaWeb == True:\n",
    "                # via WebUI\n",
    "                chat_response = askChatbot(model, event_definitions, instruction, combined_procedure_text)\n",
    "                # Extract and store the response\n",
    "                response_content = chat_response.json().get(\"message\", {}).get(\"content\", \"No response content\")\n",
    "            else:\n",
    "                # without WebUI\n",
    "                chat_response = askChatbotLocal(model, event_definitions, instruction, combined_procedure_text)\n",
    "                response_content = chat_response\n",
    "            \n",
    "            print(f\"Response from {model}:\\n{response_content}\")\n",
    "            #doc_dict[\"annotations\"] = {\n",
    "            #    \"model_name\": model,\n",
    "            #   \"events\": response_content,\n",
    "                #\"events\": response_content.get(\"events\", []) if isinstance(response_content, dict) else []\n",
    "            #}\n",
    "            annotations_list.append({\"model_name\": model, \"events\": response_content})\n",
    "            \n",
    "        except Exception as e:\n",
    "            with open(\"error.txt\", \"a\") as file:\n",
    "                file.write(f\"Error with model {model}: {str(e)}\")\n",
    "            file.close()\n",
    "        \n",
    "    doc_dict[\"annotations\"] = json.dumps(annotations_list)   \n",
    "    # Append the document dictionary to the results list\n",
    "    results.append(doc_dict)\n",
    "    break\n",
    "    \n",
    "\n",
    "# Save results\n",
    "#df = pd.DataFrame(results)\n",
    "# CSV\n",
    "#df.to_csv(\"chat_responses_with_instructions.csv\", index=False)\n",
    "# Excel\n",
    "#df.to_excel(\"chat_responses_with_instructions.xlsx\", index=False)\n",
    "# JSON\n",
    "#TODO: check format of dictionary for export\n",
    "for doc_dict in results:\n",
    "    for model in models:\n",
    "        if model in doc_dict and isinstance(doc_dict[annotations], str):\n",
    "            try:\n",
    "                doc_dict[annotations] = json.loads(doc_dict[annotations])\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not parse JSON for model {model}: {e}\")\n",
    "\n",
    "with open(\"chat_responses_with_instructions.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
