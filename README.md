# legal-llms

# Web UI
Start UI for ollama: ```open-webui serve```

Access UI on ```localhost:8080``` (also available remote via port forwarding)

# Ollama
Currently installed models:
- gemma3:12b
- llama3.3:latest                    
- deepseek-r1:8b                         
- mistral:latest                          
- incept5/llama3.1-claude:latest        
- chevalblanc/claude-3-haiku:latest    
- GandalfBaum/llama3.1-claude3.7:latest -- doesn't load